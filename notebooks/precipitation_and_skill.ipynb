{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348faae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between peak skill and upper observed predicting estimate:\n",
      "PearsonRResult(statistic=0.36568721125016423, pvalue=0.26873979493607064)\n",
      "\n",
      "Correlation between peak skill and upper observed predicted estimate:\n",
      "PearsonRResult(statistic=0.43316303775727105, pvalue=0.1832441148011558)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "peak_skill_1 = [0.136, 0.059, 0.189, 0.255, 0.386, 0.396, 0.326, 0.547, 0.443, 0.350, 0.518]\n",
    "peak_skill_2 = [0.136, 0.059, 0.189, 0.386, 0.268, 0.396, 0.326, 0.547, 0.443, 0.350, 0.518]\n",
    "\n",
    "predicting_precip = [200, 75, 200, 50, 75, 300, 150, 300, 125, 200, 150]\n",
    "predicted_precip = [200, 50, 75, 300, 150, 300, 125, 200, 150, 200, 125]\n",
    "\n",
    "print(\"Correlation between peak skill and upper observed predicting estimate:\")\n",
    "print(pearsonr(peak_skill_1, predicting_precip))\n",
    "print(\"\\nCorrelation between peak skill and upper observed predicted estimate:\")\n",
    "print(pearsonr(peak_skill_2, predicted_precip))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cbec8",
   "metadata": {},
   "source": [
    "Using the standard alpha=0.05 threshold, there is no significant evidence of linear correlation between estimated precipitation and forecast skill.\n",
    "G*Power was also used to determine the statistical power of this tests and revealed very low statistical power of around 0.1993039 and 0.2725015 respectively, leaving a chance beta of falsely accepting the null hypothesis of 0.8006961 and 0.7274985."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6872f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "jan_vals = [300,200, 50, 75, 75,]\n",
    "feb_vals = []\n",
    "mar_vals = []\n",
    "apr_vals = []\n",
    "may_vals = []\n",
    "jun_vals = []\n",
    "jul_vals = []\n",
    "aug_vals = []\n",
    "sep_vals = []\n",
    "oct_vals = []\n",
    "nov_vals = []\n",
    "dec_vals = []\n",
    "\n",
    "num_to_month = {\n",
    "    1:\"Jan\",\n",
    "    2:\"Feb\",\n",
    "    3:\"Mar\",\n",
    "    4:\"Apr\",\n",
    "    5:\"May\",\n",
    "    6:\"Jun\",\n",
    "    7:\"Jul\",\n",
    "    8:\"Aug\",\n",
    "    9:\"Sep\",\n",
    "    10:\"Oct\",\n",
    "    11:\"Nov\",\n",
    "    12:\"Dec\",\n",
    "}\n",
    "peak_skill = [0.268, 0.396, 0.326, 0.547, 0.443, 0.350, 0.518, 0.136, 0.059, 0.189, 0.255, 0.386]\n",
    "num = 0\n",
    "avg_predicting_precip = []\n",
    "for month in [jan_vals, feb_vals, mar_vals, apr_vals, may_vals, jun_vals, jul_vals, aug_vals, sep_vals, oct_vals, nov_vals, dec_vals]:\n",
    "    num += 1\n",
    "    sum_precip = sum(month)\n",
    "    mean_precip = sum_precip/len(month)\n",
    "    avg_predicting_precip.append(mean_precip)\n",
    "\n",
    "    print(f\"{num_to_month.get(num)} {mean_precip}%\")\n",
    "\n",
    "print(\"Correlation between peak skill and upper observed predicting estimate:\")\n",
    "print(pearsonr(peak_skill, avg_predicting_precip))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
